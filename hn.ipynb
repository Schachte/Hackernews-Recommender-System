{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "279ca2b7",
   "metadata": {},
   "source": [
    "# Creating a Python-based recommender system for HackerNews posts\n",
    "\n",
    "In this notebook, we will walk through how to create a simple algorithm that will recommend the top 10 posts based on our interests. The steps required to do this look like the following:\n",
    "\n",
    "1. Fetch N posts from the HN API and aggregate into a list in-memory\n",
    "2. Cleanse the data by vectorizing the list and removing stop words\n",
    "3. Create a matrix that follows the structure of TF-IDF (term frequency inverse document frequency)\n",
    "4. From here, we can vectorize our query and compute the cosine similarity of our input against our model. We will sort and rank the most similar titles to find links of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c26e84b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Let's grab top HN stories so we can generate a similarity metric off title\n",
    "response = requests.get('https://hacker-news.firebaseio.com/v0/topstories.json')\n",
    "top_stories_ids = response.json()\n",
    "\n",
    "# Define a function to fetch the title of a story given its ID\n",
    "def fetch_title(story_id):\n",
    "    response = requests.get(f'https://hacker-news.firebaseio.com/v0/item/{story_id}.json')\n",
    "    story = response.json()\n",
    "    return story['title']\n",
    "\n",
    "# Fetch the titles of the top 200 stories and store them in an array\n",
    "corpus = []\n",
    "for story_id in top_stories_ids[:500]:\n",
    "    title = fetch_title(story_id)\n",
    "    corpus.append(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bd880925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to vectorize the words and remove common words like \"of\", \"the\", etc (stopwords)\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# We won't define tfidf, but we're basically building a matrix of frequency counts\n",
    "# and understanding their relative importance to other words within the document. \n",
    "# This format will be useful when using the vectors to compute cosine similarity\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Convert the sparse matrix to a pandas DataFrame for readability\n",
    "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out(), index=corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "23a7543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def find_most_similar(query, tfidf_matrix, corpus):\n",
    "    \"\"\"\n",
    "    find_most_similar will leverage the vectors from above. We can take an input query \n",
    "    and compute the cosine similarity against all other vectors to rank the titles that are\n",
    "    the most similar.\n",
    "    \"\"\"\n",
    "    \n",
    "    relevant_results = []\n",
    "    queries = query.split(\",\")\n",
    "    stripped_array = [word.strip() for word in queries]\n",
    "    \n",
    "    for title in range(len(stripped_array)):\n",
    "    \n",
    "        # Use the vectorizer to transform the query\n",
    "        query_tfidf = vectorizer.transform([stripped_array[title]])\n",
    "\n",
    "        # Compute the cosine similarity between the query and all documents in the corpus\n",
    "        cosine_similarities = np.dot(query_tfidf, tfidf_matrix.T).toarray()[0]\n",
    "\n",
    "        # Sort the cosine similarities in descending order and return the indices of the most similar documents\n",
    "        most_similar_indices = cosine_similarities.argsort()[::-1]\n",
    "\n",
    "        # Print the most similar documents and their cosine similarity scores\n",
    "        for i in range(5):\n",
    "            index = most_similar_indices[i]\n",
    "            relevant_results.append(corpus[index])\n",
    "        \n",
    "    for res in relevant_results:\n",
    "        print(res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5ff0e104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b0c10b213f54030bb4ced1c30da68d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Query:', placeholder='Type your query here')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96458ebfd4374a26b718c3dcbd9a069d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4 is coming next week – and it will be multimodal, says Microsoft Germany\n",
      "GPT-4 is coming next week – and it will be multimodal, says Microsoft Germany\n",
      "Microsoft Bing hits 100M active users in bid to grab share from Google\n",
      "How long does Twitter have left?\n",
      "Show HN: PyBroker – Algotrading in Python with Machine Learning\n",
      "Oxy is Cloudflare's Rust-based next generation proxy framework\n",
      "How long does Twitter have left?\n",
      "Stadia’s pivot to a cloud service has also been shut down\n",
      "Circle: SVB is 1 of 6 banking partners Circle uses for ~25% part of USDC in cash\n",
      "Show HN: structured-ripgrep – Ripgrep over structured data\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "# Add a small UI for funsies\n",
    "query_box = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type your query here',\n",
    "    description='Query:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "submit_button = widgets.Button(description=\"Submit\")\n",
    "def handle_submit(button):\n",
    "    query = query_box.value\n",
    "    find_most_similar(query, tfidf_matrix, corpus)\n",
    "\n",
    "submit_button.on_click(handle_submit)\n",
    "\n",
    "display(query_box)\n",
    "display(submit_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d2ae39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
